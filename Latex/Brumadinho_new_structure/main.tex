\documentclass[a4paper,12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{setspace}
\onehalfspacing
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{indentfirst}
\usepackage{array}
\usepackage{threeparttable}
\usepackage{subcaption}
\usepackage{float}

% provisory solution until fix citations
%\newcommand{\parencite}[1]{{#1}}
%\newcommand{\textcite}[1]{{#1}}

\usepackage[authordate, backend=biber]{biblatex-chicago}

% \usepackage[style=authoryear, backend=biber]{biblatex}
\addbibresource{references.bib} 



% Personalized commands
\newcommand\foursectors{Agriculture, Industry, Services and Public Administration}

\newcommand\interestvariables{$GDP Per Capita$, $Wage$, $Log Wage$ and $Prop Employed$}


\title{
    \textbf{\LARGE Economic Impacts of the Brumadinho Dam Rupture}\\[2em]
    {\large João Marrey Mendonça}\\[13em]
}

\author{
     \parbox{0.9\textwidth}{
        \centering
        \small \textbf{Final Paper Advisor:} Prof. Solange Ledi Gonçalves\\
        \small \textbf{Final Paper Coordinator:} Prof. Rafael Pucci
    }\\[5em]
    \parbox{0.9\textwidth}{
        \centering
        \small
        Final Course Paper presented to the Faculty of Economics, Administration, Accounting and Actuarial Science\\
        of the University of São Paulo, in partial fulfillment of the requirements for the\\
        Bachelor's Degree in Economics.
    }\\[4em]
}

\date{São Paulo, 2025}

\renewcommand{\arraystretch}{1.5} % Adjusts row height; 1.0 is the default

\begin{document}

% title
\begin{titlepage}
	\maketitle
	\thispagestyle{empty}
\end{titlepage}


\newpage

% table of contents
\tableofcontents
\thispagestyle{empty}
\newpage


\listoffigures
\thispagestyle{empty}
\newpage

\listoftables
\thispagestyle{empty}
\newpage

\setcounter{page}{1}

% Abstract
\begin{abstract} 
\addcontentsline{toc}{section}{\abstractname}

In January 2019, a tailings dam from the mining company Vale ruptured in the city of Brumadinho, Brazil. It was a major disaster, with the dam's mud causing the death of 272 people, besides a series of environmental, social and economic impacts. This paper uses a matching algorithm along with the synthetic control framework to evaluate the economic repercussions of this incident on the city of Brumadinho. It focuses on the effect on GDP per capita, wages and employment, also analyzing heterogeneity to determine which economic sectors were most affected among \foursectors by using the framework on their sectoral GVA per capita. The results show a clear negative impact on GDP per capita, which was initially small, but increased over time to reach more than $R\$100,000.00$ in estimated effects. The heterogeneity analysis revealed that the affected sectors were Industry and Services, with negative impacts throughout most treatment periods, except for 2019, when Services presented positive and Industry small negative effects. This could possibly be explained by the increase in activity generated by the need to rebuild and remediate the impacts after the incident. The results did not provide enough evidence to identify any effects of the accident on sectoral GVA per capita for Agriculture or Public Administration. For wages and employment, the model also does not show evidence of impact.

\end{abstract}

\newpage

% Start of the paper
\section{Introduction}

\subsection{Context}
On the 25th of January 2019, one of the largest socio-environmental catastrophes in Brazil's history happened, the collapse of the dam at Córrego do Feijão's iron mine, in the city of Brumadinho, Minas Gerais state (MG). Figure \ref{fig:river_map} shows the course of the river, the dam location and the downstream municipalities. The accident led to $272$ deaths, a number approximately $18$ times greater than that of the Mariana disaster in 2015, a similar dam rupture incident. More than $11.7 \text{ million } m³$ of toxic mud raged through the region and contaminated the Paraopeba River.

\begin{figure}[h]
\centering
\begin{subfigure}{0.65\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/municipios_afetados_e_rio_map.png}
    \caption{Entire Minas Gerais state.}
    \label{fig:river_map_big}
\end{subfigure}
\hfill
\begin{subfigure}{0.33\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/zoom_river_map.png}
    \caption{River and surroundings.}
    \label{fig:river_map_zoom}
\end{subfigure}

\caption{River and affected municipalities map (MG state).}
\label{fig:river_map}
\end{figure}

% Maybe put image of the impact of the disaster

The Brumadinho dam was operated by the Brazilian mining company Vale S.A. since 1976. It was built as an upstream tailings dam, a frailer type of structure compared to centreline or downstream tailings dam designs (Figure \ref{fig:dam_structures}).

% Add images or figures with the \includegraphics command
\begin{figure}[h]
\centering
\includegraphics[width=0.6\textwidth]{images/dam_structures.png}
\caption{Tailing dams structures.}
\label{fig:dam_structures}
\end{figure}

The last \textit{in loco} inspection of the dam by the ANM (Brazilian National Mining Agency) had been done in 2016, with several reports stating that the agency was underfunded and did not have the resources necessary to keep track of all the mines under its responsibility. Because of this, many companies had the responsibility of inspecting their own activities, delegating this task to the auditor of their choice\footnote{See \textcite{senraBBC} for further details (text in portuguese).}. 

The main contracted auditor was Tüv Süd, which was responsible for the official inspections and the Dam Condition Stability Declarations document. In 2018, months before the accident, Tractebel was hired to do a separate review of the dam and identified serious structural risks, refusing to attest to the dam's stability. After that, Vale exerted pressure on Tüv Süd to provide the required stability declaration, with the agency ultimately conceding and providing the document despite internal warnings from some of its engineers who recognized the risk\footnote{See \textcite{jasiTCE} for further details.}.

As a result of the accident, in 2021 Vale closed a deal with the government of the state of Minas Gerais, agreeing to pay $R\$37.7 \text{ billion}$ in reparations for social, economic and environmental damages. The money has been allocated for several different programs (\textit{e.g.} $R\$4.4 \text{ billion}$ were allocated to an income transfer program), some executed by the government with Vale's funding and others executed by the company itself.

Another measure adopted was the implementation of the dam de-characterization program, which intended to eliminate all of the company's $30$ upstream dams by $2035$, having currently completed $60\%$ of the program, with $18$ eliminated dams. There were also over $23 \text{thousand}$ compensation deals reached with affected individuals, amounting to $R\$2.5 \text{ billion}$\footnote{See \textcite{rodriguesAB} for further details.}, among several other repercussions, such as the acceleration of the transition to mining without tailing dams, which represented $78\%$ of Vale's total production in Brazil in 2024\footnote{See \textcite{vale} for further details.}.

The full impact of this tragedy goes beyond scope of this paper. Previous literature indicates that $51\%$ of the devastated $297.28$ hectares of land consisted of preserved forest areas \parencite{pereira2019}. Further research indicates that the contamination of the Paraopeba River Basin exceeded the legal threshold for toxic substances, such as the metals manganese and aluminium \parencite{polignano2020}. There were more than $3845$ people directly affected \parencite{freitas2019}, among which both in-house and outsorced Vale workers represented $91\%$ of the deaths of the tragedy, $47\%$ and $44\%$ respectively \parencite{silva2020}.
\\

\subsection{Motivation}
This work adds to the  disaster literature by empirically evaluating the economic effects of the rupture of the Brumadinho tailings dam. The disaster literature has grown a lot in recent decades, especially due to the effects of climate change. Although Brumadinho's episode is a man made disaster, it is also related to the climate change part of this literature, because both man made and climate change induced catastrophes lead to socio-economic and environmental impacts.

Authors have estimated the impacts of disasters in several different contexts. \textcite{coffman2012} used the synthetic control method to estimate the effects of a 1992 hurricane on the Hawaiian island of Kauai, showing that the island's population was still $12\%$ smaller $18$ years after the disaster than it would have been had the hurricane not occurred. \textcite{belasen2008} use the generalized diff-in-diff technique and data from the US state of Florida to understand how hurricanes affect the labor market, finding a slight increase on the wage of $4\%$ on the first quarter after the incident. In the Brazilian context, \textcite{matsunaga2020} uses the diff-in-diff framework to evaluate the repercussions that the Mariana dam collapse, a similar incident, had on mental health, finding an increase in the number of hospitalizations for mental health disorders in the affected population. 

For the case of Brumadinho's incident, there does not seem to be any robust empirical estimation of the economic effects of the disaster. This presents itself as a gap in the literature, which this paper sets out to fill by providing a robust quantitative analysis of the economic impact.

Methodologically, this paper builds on the work of \textcite{abadie2003}, \textcite{abadie2010} and \textcite{abadie2015}, using the synthetic control method to construct an estimated counterfactual for Brumadinho, which allows quantification of the effects of the dam rupture on the variables of interest. This work restricts its scope to the economic impact of the disaster, focusing on macroeconomic and labor market variables. This problem presents itself as an interesting object of study, since the effects of the disaster are not obvious. Although it is tempting to assume a negative impact on GDP per capita, wages and employment, the reparations program makes the net effect become uncertain. This becomes clear when we see that the nominal GDP of Brumadinho in 2019 was $R\$2.5 \text{ billion}$, but the compensation agreement alone was of $R\$37.7 \text{ billion}$.

The remainder of this paper is organized as follows. Section \ref{methodology} describes the database, the variables specification and the empirical methodology. Section \ref{results} discusses the results for the interest variables \interestvariables. Section \ref{heterogeneity} analyzes the heterogeneity of the effects on $4$ different economic sectors \foursectors. Section \ref{robustness} checks the robustness of results. Section \ref{conclusion} concludes.
\\

\section{Methodology} \label{methodology}

\subsection{Overview}
To estimate the impact of the disaster on the variables of interest \interestvariables, the synthetic control method was utilized, as presented in \textcite{abadie2003} and further developed in \textcite{abadie2010}. The donor pool was restricted to municipalities in the state of Minas Gerais (MG), which amounts to a total of 852 units when excluding Brumadinho, the treated unit. Since a donor pool that is too large can lead to overfitting and make synthetic control estimation unfeasible due to computational requirements, a matching technique was employed to select the 30 nearest-neighbor municipalities to Brumadinho according to a Manhattan distance measure, ensuring a donor pool similar to the treated unit.

After the matching, the synthetic control is estimated using pre treatment period data, which spans from 2002-2018 , though some variables have available data only starting from 2007. This provides an estimated counterfactual version of Brumadinho, allowing the calculation of the estimated treatment effects (gaps) for the post treatment period (after 2019) and the usage of placebo tests to perform inference.

Going further, subsection \ref{database_and_variables} explains the origin and composition of the data used, also presenting its variables. After that, subsections \ref{matching}, \ref{model} and \ref{inference} explain the methodology described in the last paragraph in more depth.
\\

\subsection{Database and Variables} \label{database_and_variables}
The database used for the model is composed of municipal level panel data. It was constructed using data from four different sources \textcite{ibge2025}, \textcite{atlasBR} and \textcite{basedados2025}. Table \ref{tab:original_variables} displays the variables used, their time periods and data sources. The "Breakdown" column is used so that related variables can be displayed in a single row, with their different dimensions being described in this column. For example, the database has gross value added data ($GVA$), with variables for the total $GVA$ and 4 different sectoral $GVA$ breakdowns of this total (\foursectors), making up 5 different variables. The table gathers these 5 variables into a single row, assigning "Gross Value Added" to the "Measure" column and describing the different 5 different breakdowns of this measure on the "Breakdown" column. 

{\begin{table}[htb!]
\small
\begin{threeparttable}
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|>{\centering\arraybackslash}p{3cm}|>{\centering\arraybackslash}p{3cm}|>{\centering\arraybackslash}p{3cm}|>{\centering\arraybackslash}p{3cm}|}
\hline

\textbf{Measure} & \textbf{Breakdown} & \textbf{Time Period} & \textbf{Data Source} 
\\ \hline

Gross Value Added ($GVA$) & Total and 4 Sectors\tnote{1} & 2002-2021 & \parencite{ibge2025} 
\\ \hline

$GDP$ & Total and Per Capita & 2002-2021 & \parencite{ibge2025} 
\\ \hline

Population ($POP$) & Total & 2002-2021 & \parencite{ibge2025} 
\\ \hline

Rural Population & Total & 2010 & \parencite{ibge2025} 
\\ \hline

$IDHM$\tnote{2} (Municipal HDI) & Total, Education, Longevity and Income & 2010 & \parencite{atlasBR} 
\\ \hline

Transfers from Bolsa Família\tnote{3} & Per Capita & 2013-2017 & \parencite{atlasBR} 
\\ \hline

$GINI$ & Total & 2010 & \parencite{ibge2025} 
\\ \hline

Literacy Rate & Total & 2010 & \parencite{ibge2025} 
\\ \hline

Proportion of Population in Minimum Wage Bracket & Brackets: 0-1; 1-2; 2-5; 5-10; 10+ Minimum Wages & 2010 & \parencite{ibge2025} 
\\ \hline

Average Wage ($Wage$) & Total & 2002-2024 & \parencite{basedados2025}
\\ \hline

Number of Companies & Total & 2002-2023 & \parencite{basedados2025}
\\ \hline

Average Total Employment ($Employed$) & Total & 2007-2024 & \parencite{basedados2025}
\\ \hline

\end{tabular}
}
\begin{tablenotes}
\footnotesize
\centering \item [1] \foursectors.

\centering \item [2] IDHM is an adaptation of the HDI, for municipalities in Brazil.

\centering \item [3] Bolsa Família is a conditional cash transfer program in Brazil.

\end{tablenotes}
\end{threeparttable}
\caption{Original variables, their time periods and respective data sources.}
\label{tab:original_variables}
\end{table}}


{\begin{table}[htb!]
\small
\begin{threeparttable}
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|>{\centering\arraybackslash}p{3cm}|>{\centering\arraybackslash}p{3cm}|>{\centering\arraybackslash}p{3cm}|>{\centering\arraybackslash}p{3cm}|}
\hline

\textbf{Measure} & \textbf{Breakdown} & \textbf{Time Period} & \textbf{Formula} 
\\ \hline

$GVA Per Capita$ & Total and 4 Sectors\tnote{1} & 2002-2021 & $\frac{GVA}{POP}$ 
\\ \hline

Sector's Share of Total GVA & 4 Sectors & 2002-2021 & $\frac{GVA_{Sector}}{GVA_{Total}}$ 
\\ \hline

Average Proportion of Employment ($Prop Employed$) & Total & 2007-2021 & $\frac{Employed}{POP}$ 
\\ \hline

Natural Log of Average Wage ($Log Wage$) & Total & 2002-2024 & $\ln{Wage}$ 
\\ \hline

\end{tabular}
}
\begin{tablenotes}
\footnotesize
\centering \item [1] \foursectors.

\end{tablenotes}
\end{threeparttable}
\caption{Compound variables, their time periods and formulas.}
\label{tab:compound_variables}
\end{table}}

Among the presented variables, 3 of them were built using SQL queries and python to extract them from \textcite{basedados2025} and save them to the database, since this source contains unidentified person level data and municipal level data is needed. $Wage$ was built by calculating the mean of the average monthly wage for each given municipality and year using the RAIS Vínculos database. The Number of Companies variable was built using RAIS Estabelecimentos by counting the number of rows when grouping by year and municipality, which corresponds to the number of firms that reported data for each city and year, since in this data source each row contains a unique firm. 
Lastly, $Employed$ was built using the CAGED database, which contains monthly hiring and layoff data, allowing the calculation of the monthly total employment change. With this measure, we use the total employment on December 2006 from RAIS Vínculos to iteratively calculate the monthly total employment and, with it, the Average Total Employment ($Employed$) for each given year and municipality. This is important because employment measures calculated from the RAIS Vínculos database can be obtained only for December of each year, but employment in any given month is very volatile and a yearly average helps decrease volatility, improving the synthetic control's fit for the pre treatment period.  

Other compound variables were created using the original ones. This is important because at times the most relevant variables for the study are not immediately available via the official sources, but can be obtained by creating other variables that alter existing data in a meaningful way. For example, we obtain the per capita $GVA$ measures, dividing the $GVA$ by the population. This data is more useful in many applications, such as comparing the relative size of the four sectors between municipalities with very different populations. 


Another important manipulation was the calculation of $LogWage$, a logarithmic transformation of the $Wage$ variable. This is important since wages tend to present exponential growth time series and this transformation log-linearizes them. Besides that, the treatment effect estimators obtained for this transformation can be interpreted approximately as the percentage effect:

\begin{equation}
\label{eq:log_effect}
\begin{aligned}
\delta &= \ln (Wage^I) - \ln (Wage^U) = \ln \left(\frac{Wage^I}{Wage^U}\right) =  \ln \left(\frac{Wage^U + \Delta Wage}{Wage^U}\right) = \ln \left(1 + \frac{\Delta Wage}{Wage^U}\right)  \Rightarrow \\
\delta &\approx \frac{\Delta Wage}{Wage^U}, \quad \text{since } \Delta Wage = Wage^I - Wage^U\text{ and } \ln(1+x) \approx x \text{ for small } x.
\end{aligned}
\end{equation}

Where $\delta$ is the treatment effect estimator, $Wage^U$ is the $Wage^I$ variable in the absence of the intervention and $Wage^I$ is the wage variable in the presence of it. Table \ref{tab:compound_variables} displays the created variables, specifying how they were obtained.
\\


\subsection{Matching} \label{matching}
The matching algorithm is used to limit the donor pool, preventing overfitting and making estimation feasible. This process is applied for each of the interest variables independently, creating separate donor pools for them, these different divisions will be referred to as "interest groups" from here. This ensures that the groups from which the synthetic controls will be built are optimized to better recreate the path of the specific interest variable for which they were matched, while preventing overfitting.

The process starts by selecting the variables on which the Manhattan distance measure will be calculated, these variables are specific to each of the interest groups and were selected to improve the pre treatment fit of their synthetic control. Each observed pre treatment year for a variable is considered as its own independent variable, being then used to calculate the distance, we call this new set of variables "matching variables". For example, if $GDP Per Capita$ is included in the matching, there would be a variable created for the 2002 GDP named $GDP Per Capita 2002$, one for 2003 named $GDP Per Capita 2003$ and so on for every year until 2018, they would all be treated as separate matching variables for the purpose of calculating the distance. 

%\footnote{See the Appendix for a list the variables used for each group.}

Each matching variable is then standardized by calculating its z-score, so that scale does not affect the result. Let the sample mean of the matching variable x be $\bar{x}$, the sample standard deviation of x ($std_x$) is:

\begin{equation}
\label{eq:std}
{std_x = \sqrt{\sum\limits_{i=1}^{N} \frac{(x_i - \bar{x})^2}{N-1}}}
\end{equation}

For each observation $x_i$ of x, its z-score $z_{x_i}$ can be calculated as:

\begin{equation}
\label{eq:zscore}
{z_{x_i} = \frac{x_{i}-\bar{x}}{std_x}}
\end{equation}

The z-score of the matching variables substitute the original ones to calculate the distance. From now on, when the matching variables are mentioned, it refers to the calculated z-score.

Suppose there are $N+1$ municipalities of which units $2$ through $N+1$ are untreated and $1$ is treated, consider, as well, that each of them has $P$ matching variables. For the unit $n$, its set of variables can be represented by the vector $MV_n$, this vector has $P$ dimensions, one for each matching variable. We can then represent each element of $MV_n$ as $MV_{pn}$, which is matching variable $p$ of unit $n$. The distance between the treated unit and unit $n$ can then be calculated as:

\begin{equation}
\label{eq:distance}
{\sum\limits_{p=1}^{P} \left|\frac{MV_{pn} - MV_{p1}}{MV_{p1}}\right|}
\end{equation}

Where $\frac{MV_{pn} - MV_{p1}}{MV_{p1}}$ represents the percent difference between the two units. 

The distance is calculated for each of the municipalities of Minas Gerais, excluding Brumadinho, for a total of 852 distance measures. The municipalities with the smallest 30 distance measures are selected to compose the donor pool of the interest group for which the matching was made.
\\

\subsection{Model} \label{model}
After the donor pool is defined by the matching algorithm, the synthetic control method is used to evaluate the impact, as presented in \textcite{abadie2003} and further developed in \textcite{abadie2010}. This subsection describes this model, explaining the math and intuition behind its estimation. For a more in depth explanation of synthetic control, read \textcite{abadie2021}. To estimate this model with the data, the R package "Synth", presented in \textcite{abadie2011}, is used.

Suppose there are $N+1$ municipalities, of which units $2$ through $N+1$ are untreated and $1$ is treated. Additionally, there are $T$ periods in total, with $T_0$ periods before treatment ($t = T_0$ is the last period before the intervention). The outcome of interest for unit n and period t is $Y_{nt}$, there is also a prediction vector $X_n$ of $K$ dimensions for any unit $n$ ($K$ predictors), where $X_n = \{X_{1n}, ..., X_{Kn}\}$ and $X_{kn} \quad k \in \{1, .., K\}$ is a predictor for the outcome variable for unit $n$ and could have been observed in any time period $t$ before the intervention ($t \le T_0$), but not after. It is important to note that the vector $X_n$ can, and probably should, contain pre intervention values of the outcome as predictors. Thus, the matrix $X_0$ that collects all prediction vectors for the untreated units is constructed as $X_0 = \begin{pmatrix} X_2 & ... & X_{N+1} \end{pmatrix}$.

For unit $n$, the potential outcome without intervention for period $t$ is defined  as $Y_{nt}^U$ and the potential outcome with intervention for the same period is $Y_{nt}^I$, they represent the value that the outcome would assume for unit $n$ in a scenario without and with treatment, respectively, for period $t$. For any unit $n$ such that $n \in \{2, ..., N+1\}$ (untreated units), it is true that the realized outcome is equal to the potential outcome without intervention for all periods $Y_{nt} = Y_{nt}^U \quad \forall t$, because these units are not treated by assumption. On the other hand, for $n=1$ (the treated unit), the realized outcome before treatment is equal to the potential outcome without intervention and after treatment it is equal to the potential outcome with intervention, so that $Y_{1t} = Y_{1t}^U \quad t \le T_0$ and $Y_{1t} = Y_{1t}^I \quad t > T_0$.

The treatment effect for unit $1$ in period $t$ is then defined as $\tau_{1t} = Y_{1t}^I - Y_{1t}^U$ and our goal is to estimate it for periods after the intervention (estimate $\tau_{1t} \quad t> T_0$). Since $Y_{1t} = Y_{1t}^I \quad t > T_0$, the equation can be rewritten for post intervention periods as:

\begin{equation}
\label{eq:treatment_effect}
\tau_{1t} = Y_{1t} - Y_{1t}^U\quad t>T_0
\end{equation}

Now, the problem boils down to finding an estimate for $Y_{1t}^U$, which is the outcome value for unit $1$ and period $t$ if it had not been treated, that is, the counterfactual outcome. The way that the synthetic control tackles this is by creating a weighted average of the untreated units from the donor pool, this is the so called synthetic control, because it is an artificial control unit built from the donor pool of untreated units. The synthetic control estimator for the counterfactual outcome is then:

\begin{equation}
\label{eq:counterfactual_outcome}
\hat{Y}_{1t}^U = \sum_{n=2}^{N+1} w_n Y_{nt}
\end{equation}

Where $w_n$ represents the weight attributed to unit $n$. The weights are restricted to be nonnegative and sum to one, which is a reasonable assumption and important for the interpretability of the estimator. The treatment effect estimator becomes:

\begin{equation}
\label{eq:treatment_effect_estimator}
\hat{\tau}_{1t} = Y_{1t} - \hat{Y}_{1t}^U \quad t>T_0
\end{equation}

Thus, the treatment effect estimator is the difference between the outcome of the treated unit and that of the synthetic control, this difference will then be called the gap between the two trends. This name will be used in the section \ref{results} when presenting the results. The gaps will also be calculated for the pre intervention period, being expected to be close to 0.

The problem that arises now is the choice of the weights, the goal is to choose the optimal vector of weights $W^* = \begin{pmatrix} w_2 & ... & w_{N+1} \end{pmatrix}^T$ so that the best treatment effect estimator is obtained. \textcite{abadie2003} propose solving the following minimization problem for choosing $W^*$:  

\begin{equation}
\label{eq:w_choice_min}
\begin{aligned}
W^* & = \arg \min_{W} || X_1 - X_0W|| = \arg \min_{W} (\sum \limits_{k=1}^Kv_k(X_{k1} - w_2X_{k2} - ... - w_{N+1}X_{kN+1})^2)^{1/2} \\
\text{s.t.} &\quad \sum_{n=2}^{N+1} w_n = 1; \quad
 w_n \ge 0 \quad \forall n
\end{aligned}
\end{equation}

$|| X_1 - X_0W||$ is a weighted measure distance between the predictors for the treated unit and the synthetic control defined by $W$. Thus, solving this problem means finding the set of weights that renders the smallest distance measure between the treated unit and the synthetic control, in other words, it is simply finding the most similar synthetic control according to the defined distance measure. The measure distance weights are contained in the vector $V = \begin{pmatrix} v_1 & ... & v_K \end{pmatrix}^T$, and define how important each predictor is for the estimation, so that the higher $v_k$ is, the more important it is to minimize the difference $(X_{k1} - w_2X_{k2} - ... - w_{N+1}X_{kN+1})^2$ for the predictor k, relative to this difference for the other predictors.

The problem of defining the optimal vector of measure weights $V^*$ remains, since every choice of $V^*$ will render a specific solution $W(V^*)$. \textcite{abadie2003} propose solving the following problem to choose $V^*$:

\begin{equation}
\label{eq:v_choice_min}
\begin{aligned}
V^* & = \arg \min_{V} (\sum \limits_{t=1}^{T_0}(Y_{1t} - w_2(V)Y_{2t} - ... - w_{N+1}(V)Y_{N+1t})^2)^{1/2} \\
\text{s.t.} &\quad v_k \ge 0 \quad \forall k
\end{aligned}
\end{equation}

Solving this means selecting $V^*$ so that the associated set of weights $W(V^*)$ generates the smallest difference between the outcomes of the treated unit and the synthetic control. 

The entirety of this process is important to find a synthetic control that is not overfit, but actually meaningful. If the weights for our counterfactual estimator were found simply by minimizing the difference between outcomes and not of all the other predictors as in equation \ref{eq:w_choice_min}, then the risk of overfitting would be high. In that case it would be much more likely to obtain a set of weights that fit very well the pre treatment path of the outcome for the treated unit, but that generate a synthetic control that is very different from the treated unit on its characteristics, possibly generating a post treatment path for the synthetic control that does not approximate the counterfactual outcome of the treated unit $\hat{Y}_{1t}^U \quad t>T_0$. Minimizing the difference on the other predictors helps prevent this, because it generates a set of weights that approximate not only the outcome path, but also the observable characteristics (the predictors), generating an estimate that is more robust to the overfitting problem.

Another important thing to note is that having a good synthetic control entails observing a good pre treatment fit on the outcome path, because if the pre treatment fit is poor, chances are that the post treatment outcome will not estimate the counterfactual $\hat{Y}_{1t}^U \quad t>T_0$ well. For this reason, it is essential to have a long pre intervention time span, meaning that $T_0$ should be as large as possible.
\\

% For the validity of the synthetic control estimators, some assumptions are necessary. A common set of assumption well accepted in economic literature would be: common support, conditional independence, absence of external shocks, absence of spill-over effects and absence of anticipation effect.
% \\


\subsection{Inference} \label{inference}
The goal of the inference here is to define a way of testing the null hypothesis of no treatment effect, against the alternative hypothesis of existence of treatment effect. As proposed by \textcite{abadie2010}, a placebo distribution for the absence of treatment can be calculated iteratively using the donor pool units. This means calculating a synthetic control estimator for each of the units in the donor pool, which is called a placebo test. 

This process will iterate through the donor pool, selecting one unit at a time, say unit $n$. It will then construct a placebo donor pool for this unit, which will be the original donor pool excluding unit $n$ itself, notice that the treated unit is not included in this group. Then, the synthetic control estimator described in subsection \ref{model} will be obtained for unit $n$ using its placebo donor pool.

Once the iteration is done, there will be $N$ placebo test estimations, which can be used as a comparison to the results for the treated unit. The idea is to see if the result obtained from the synthetic control of the treated unit is significantly more extreme than that of the placebo tests. A way to do that is to use the MSPE as a measure of fit, so that a more extreme result would render a higher MSPE, a worse fit. 

The problem with this is that since the donor pool was designed to have units similar to the treated one, it does not necessarily contain similar enough units to each of the untreated ones, so that when the placebo tests are calculated it is common to see many estimations with very poor pre treatment fit. Synthetic controls that have poor pre treatment fit are much more likely to present poor post treatment fit, even if there is no intervention, which would make our results for the treated unit seem less extreme, even though they are not.

\textcite{abadie2010} propose using a post/pre MSPE ratio ($RatioMSPE$) that helps correct this issue. It does that by comparing how extreme the post treatment MSPE is in relation to the pre treatment MSPE, instead of just comparing post treatment MSPE alone. The $RatioMSPE_n$ is calculated for unit $n$ through:

\begin{equation}
\label{eq:ratio}
RatioMSPE_n = \left(\frac{T_0}{T - T_0} \frac{\sum \limits_{t=T_0+1}^{T}\left(Y_{nt} - \hat{Y}_{nt}^U\right)^2}{\sum \limits_{t=1}^{T_0}\left(Y_{nt} - \hat{Y}_{nt}^U\right)^2}\right)^{1/2}
\end{equation}

Another adjustment suggested by \textcite{abadie2010} to prevent the problem is to discard placebo tests that have a pre treatment MSPE $MSPE_{t \le T_0}$ higher than a threshold of the treated unit's pre treatment MSPE. The threshold used in this paper if of $5$ times, so that any placebos $n$ such that $MSPE_{n,t \le T_0} > 5MSPE_{1,t \le T_0}$ are discarded from the placebo test group. Say that there were $P$ units that satisfied this condition, this means that the final number of placebo units used will be $N-P$. We can then construct a set containing the indexes of the remaining units in the placebo test group:

\begin{equation}
\label{eq:placebo_indexes}
\mathcal{P} = \{n: n \in \{2, ..., N+1\} \quad and \quad  MSPE_{n,t \le T_0} \le 5MSPE_{1,t \le T_0} \}
\end{equation}

When the placebo tests that pass the threshold are discarded and $RatioMSPE$ is calculated for all of the remaining, a pseudo distribution for the absence of treatment against which to compare $RatioMSPE_1$ is naturally obtained. A pseudo p-value is then calculated by:

\begin{equation}
\label{eq:p_value}
p = \frac{1}{N - P} \sum_{n \in \mathcal{P}} 
I\!\left(\text{RatioMSPE}_1 \ge \text{RatioMSPE}_n\right)
\end{equation}

Where \( I(\cdot) \) is an indicator function that is equal to 1 if the condition is satisfied and 0 otherwise. The pseudo p-value ($p$) measure indicates the proportion of placebo units that had a $RatioMSPE$ at least as extreme as the one obtained for the treated unit.

The standard threshold for $p$ is assumed, so that if $p < 0.05$ the null hypothesis of no treatment effect is rejected. It is important to note that in this last step, where the null hypothesis is tested, the evaluation consists of a joint significance test for all of the post treatment treatment effects (gaps) together. 
\\

\section{Results} \label{results}

\subsection{Overview}
In this section we present and interpret the results of the model for all interest variables, each on their own subsections. In the subsections, we present the synthetic control results with a graph containing the time series for Brumadinho and its synthetic control, and later another graph showing the gaps between the two. Lastly, we display the graphs for the placebo distribution and the inference results.

The interest variables are \interestvariables. $Wage$ and $Log Wage$ are presented to analyze the difference in both specifications, since it is standard practice in economic literature to use a logarithmic transformation in wage variables\footnote{See subsection \ref{database_and_variables} for further information.}.
\\

\subsection{GDP Per Capita} \label{gdp_per_capita}
% \begin{figure}[h]
% \centering
% \includegraphics[width=0.8\textwidth]{images/pib_municipios_map.png}
% \caption{Matched donor pool for GDP Per Capita.}
% \label{fig:gdp_map}
% \end{figure}
This subsection analyzes the synthetic control results for $GDP Per Capita$. Figure \ref{fig:gdp_time_series} displays the variable's time series for both Brumadinho and the synthetic control. There is a very good fit before treatment, as seen by how the trend of the synthetic unit for the variable of interest mimics almost perfectly that of Brumadinho. In the post treatment period, a gap opens between the two, with Brumadinho's GDP per capita being much lower than that of its control. It is noticeable that the difference between the two trends increases with time, reaching a much higher level in the last observed treatment year (2021). 

\begin{figure}[!h]
\centering
\includegraphics[width=0.7\textwidth]{images/gdp_2.png}
\caption{GDP Per Capita treated and synthetic trends.}
\label{fig:gdp_time_series}
\end{figure}

The evolution of the gaps can be observed in Figure \ref{fig:gdp_gaps}. Here it is clearly seen how the $GDP Per Capita$ was impacted by the disaster. In the first year the gap is not very large, being close in dimension to that of 2010, before the treatment, but in 2021, the last treatment year, the gap is greater than $R\$ 100,000.00$, which represents a significant impact on the variable.

\begin{figure}[!h]
\centering
\includegraphics[width=0.7\textwidth]{images/gdp_5.png}
\caption{GDP Per Capita gaps.}
\label{fig:gdp_gaps}
\end{figure}

Even though the results look good visually, it is important to use inference to have a way of analyzing the results objectively. To achieve that, a placebo distribution is generated by calculating a synthetic control for each unit in the donor pool, and keeping the ones with a good enough fit\footnote{See subsection \ref{inference} for further information.}. 

\begin{figure}[!h]
\centering
\includegraphics[width=0.7\textwidth]{images/gdp_6.png}
\caption{GDP Per Capita placebo gaps.}
\label{fig:gdp_placebo_gaps}
\end{figure}

In Figure \ref{fig:gdp_placebo_gaps} the resulting gaps of the placebo tests, after the ones with poor fit are removed, are shown, along with the gaps for Brumadinho. From a visual inspection, the post treatment gaps for the treated unit seem more extreme than those of most of the placebo tests.

The visual inspection of the gaps for the placebo test alongside that of Brumadinho give a better comparison measure than looking at Brumadinho's gaps alone. However, it is important to consider that Brumadinho's synthetic control has a better pre treatment fit than most of the other placebo units and that units with poor pre treatment fit are more likely to present extreme post treatment gaps, even without treatment. 

To correct for the difference in fit, the post/pre MSPE ratio ($RatioMSPE$) is used\footnote{See subsection \ref{inference} for further information.}, as proposed by \textcite{abadie2010}. This variable indicates how big the post treatment fit is relative to the pre treatment fit, with its use being more appropriate to analyze how extreme Brumadinho's gaps are compared to the placebo tests.

\begin{figure}[!h]
\centering
\includegraphics[width=0.7\textwidth]{images/gdp_7.png}
\caption{GDP Per Capita placebo distribution.}
\label{fig:gdp_placebo_distribution}
\end{figure}

A placebo distribution for the donor pool's $RatioMSPE$ and a pseudo p-value are presented in Figure \ref{fig:gdp_placebo_distribution}. We can see that Brumadinho's $RatioMSPE$ is over two times more extreme than that of any unit from the donor pool, which renders a p-value of $0$. Thus, it is concluded that the effect of the dam rupture on $GDPPerCapita$ was negative and statistically significant.
\\

\subsection{Wage} \label{wage}

% \begin{figure}[!h]
% \centering
% \includegraphics[width=0.7\textwidth]{images/wage_2.png}
% \caption{Wage treated and synthetic trends.}
% \label{fig:wage_time_series}
% \end{figure}

In this subsection the model's results for $Wage$ are analyzed. Figure \ref{fig:wage_time_series} displays the time series of this variable for Brumadinho and its synthetic control. 

\begin{figure}[!h]
\centering
\includegraphics[width=0.7\textwidth]{images/wage_2.png}
\caption{Wage treated and synthetic trends.}
\label{fig:wage_time_series}
\end{figure}

Before treatment, the path for the synthetic control seems to follow that of Brumadinho, although it is not as close as for the $GDPPerCapita$ variable. This is likely due to wage variables being much more volatile than extremely aggregate measures such as gdp per capita. 

Nevertheless, there is a good pre treatment fit. In the post intervention period, the path of the control also closely matches that of the treated unit, with visual inspection suggesting that the only relatively large gap is obtained in the last observed treatment year (2024).

\begin{figure}[!h]
\centering
\includegraphics[width=0.7\textwidth]{images/wage_5.png}
\caption{Wage gaps.}
\label{fig:wage_gaps}
\end{figure}

In Figure \ref{fig:wage_gaps} the gaps between the time series are plotted and provide a different view of the results. It seems that the gaps sequence for the post treatment period is not very different from that of the pre treatment period, except for the last treatment year, where a gap slightly larger than the previous ones is obtained. However, an objective test is still necessary to have a conclusive result. 

\begin{figure}[!h]
\centering
\includegraphics[width=0.7\textwidth]{images/wage_6.png}
\caption{Wage placebo gaps.}
\label{fig:wage_placebo_gaps}
\end{figure}

Figure \ref{fig:wage_placebo_gaps} provides the resulting gaps for the placebo tests alongside those of Brumadinho. The image shows that the treated unit's gaps are not as extreme as those of most of the placebo tests for most post intervention periods.


This insight becomes clearer when observing Figure \ref{fig:wage_placebo_distribution}. In this image, the placebo distribution for the MSPE ratio variable ($RatioMSPE$) is plotted alongside Brumadinho's obtained ratio value. This view shows that the treated unit's ratio is much less extreme than that of most placebo tests. 

\begin{figure}[!h]
\centering
\includegraphics[width=0.7\textwidth]{images/wage_7.png}
\caption{Wage placebo distribution.}
\label{fig:wage_placebo_distribution}
\end{figure}

Finally, the conclusion that Brumadinho's ratio is not extreme is confirmed by a high pseudo p-value of $0.7$, which means that $70$\% of the placebo tests had a ratio at least as extreme as that of the treated unit. Thus, it is concluded that there is not enough evidence to reject the null hypothesis of no effect from the dam rupture on $Wage$.
\\

\subsection{Log Wage} \label{log_wage}
In this subsection, the results of the synthetic control model for $LogWage$ are analyzed. This is a different specification of the model for the wage variable, using a logarithmic transformation, which is a standard procedure in economic literature as introduced by \textcite{mincer1974}. 

\begin{figure}[!h]
\centering
\includegraphics[width=0.7\textwidth]{images/ln_wage_2.png}
\caption{Log Wage treated and synthetic trends.}
\label{fig:ln_wage_time_series}
\end{figure}

This kind of variable manipulation is useful because it provides gaps (treatment effect estimators) that can be interpreted as the approximate percentage rate return\footnote{See subsection \ref{database_and_variables} for further information.}. 

\begin{figure}[!h]
\centering
\includegraphics[width=0.7\textwidth]{images/ln_wage_5.png}
\caption{Log Wage gaps.}
\label{fig:ln_wage_gaps}
\end{figure}

Another important property of this transformation is that it log-linearizes wage time trends, since this variable tends to have exponential growth over time. Both of these properties can help achieve a better synthetic control estimator and more interpretable results, the percentage changes.

\begin{figure}[!h]
\centering
\includegraphics[width=0.7\textwidth]{images/ln_wage_6.png}
\caption{Log Wage placebo gaps.}
\label{fig:ln_wage_placebo_gaps}
\end{figure}

Figure \ref{fig:ln_wage_time_series} plots the $LogWage$ variable time trends for the treated and synthetic control units for comparison. Once again, the pre intervention $LogWage$ control time series seems to fit Brumadinho's series well, although it is not as good the obtained fit for the $GDP Per Capita$ variable. In the post intervention period, the synthetic control also seems to closely match the Brumadinho's path for the variable of interest. This indicates that there might not have been any treatment effect on the variable, since the built control does not deviate much from the treated unit.

\begin{figure}[!h]
\centering
\includegraphics[width=0.7\textwidth]{images/ln_wage_7.png}
\caption{Log Wage placebo distribution.}
\label{fig:ln_wage_placebo_distribution}
\end{figure}

Figure \ref{fig:ln_wage_gaps} provides a better view of the difference between the time trends of both variables. The post intervention gaps appear to not deviate much from the pre intervention gaps, pointing towards the absence of impact on this variable. To further analyze this possibility, placebo tests were performed for statistical inference.

In Figure \ref{fig:ln_wage_placebo_gaps}, the gaps for Brumadinho and the placebo tests are presented. It seems that the gaps for the treated unit are not as extreme as most of those for the placebo tests, which further indicates that there was no treatment effect on the $LogWage$ variable.

To objectively assess the existence of intervention effect, Figure \ref{fig:ln_wage_placebo_distribution} presents the placebo distribution of the MSPE ratio ($RatioMSPE$), alongside the ratio of Brumadinho. It becomes clear that the treated unit's result is not more extreme than most of the placebo distribution, with a calculated pseudo p-value of $0.767$, indicating that $76.7$\% of the placebo tests have a ratio at least as extreme as that of the treated unit. 

Thus, it is concluded that there is not enough evidence to reject the null hypothesis that the dam rupture did not impact $LogWage$.
\\

\subsection{Prop Employed} \label{prop_employed}
This subsection analyzes the model's results for $PropEmployed$. This variable is chosen instead of $Employed$ for the analysis of the effect on employment, because it represents total employment as a proportion of the population, a measure that is not affected by municipality size as the raw employment is. This makes it more appropriate for the synthetic control analysis, since an untreated unit of different size to the treated one, but very similar in other relevant characteristics will likely not present a comparable $Employed$ trend, but will present a very close $PropEmployed$ trend to the treated one.

\begin{figure}[!h]
\centering
\includegraphics[width=0.7\textwidth]{images/prop_emp_2.png}
\caption{Proportion of Employed Population treated and synthetic trends.}
\label{fig:prop_emp_time_series}
\end{figure}

Figure \ref{fig:prop_emp_time_series} presents the time trends of $PropEmployed$ for both Brumadinho and the synthetic control. Despite the existence of more noise than in the other variables' analysis, the trends appear to follow a relatively close path in the pre treatment period. 

\begin{figure}[!h]
\centering
\includegraphics[width=0.7\textwidth]{images/prop_emp_5.png}
\caption{Proportion of Employed Population gaps.}
\label{fig:prop_emp_gaps}
\end{figure}

The noise probably stems from different reasons, such as the available pre treatment period being shorter for this variable (starts in 2007), making it more difficult for the matching and synthetic control algorithms to find a good result. It is also likely that the employment data is more volatile, also disturbing the process.

After the intervention, a small gap is seen between both units, indicating that there might have been a positive impact on employment. However, the difference does not look more extreme than some of the differences observed before treatment, so further evaluation is necessary.

The gaps displayed in Figure \ref{fig:prop_emp_gaps} provide new insight, confirming the previous suspicion that the post treatment gaps are not more extreme than some of the gaps before the intervention. The placebo test inference is used to obtain an objective assessment on the significance of these results. 

\begin{figure}[!h]
\centering
\includegraphics[width=0.7\textwidth]{images/prop_emp_6.png}
\caption{Proportion of Employed Population placebo gaps.}
\label{fig:prop_emp_placebo_gaps}
\end{figure}

Figure \ref{fig:prop_emp_placebo_gaps} shows the gaps for Brumadinho and the placebo tests. The post treatment gaps for the treated unit do not appear more extreme than those of the placebo tests, which indicates that the positive gaps found are likely not statistically significant. The placebo distribution is used, to provide a conclusive analysis.

\begin{figure}[!h]
\centering
\includegraphics[width=0.7\textwidth]{images/prop_emp_7.png}
\caption{Proportion of Employed Population placebo distribution.}
\label{fig:prop_emp_placebo_distribution}
\end{figure}

In Figure \ref{fig:prop_emp_placebo_distribution} the placebo distribution for $RatioMSPE$ is plotted alongside the ratio variable for Brumadinho. The pseudo p-value is $0.793$, meaning that $79.3\%$ of the placebo tests have a calculated $RatioMSPE$ at least as extreme as the one for the treated unit. This leads to the conclusion that there is not enough evidence to reject the null hypothesis that the dam rupture did not impact $PropEmployed$.
\\

\section{Heterogeneity} \label{heterogeneity}

\subsection{GVA Per Capita}
In this subsection, we analyze the impact of the disaster on the 4 sectors' gross value added per capita variable. These $GVAPerCapita$ measures represent a breakdown of $GDPPerCapita$, previously evaluated in subsection \ref{gdp_per_capita}, into its components of the 4 sectors \foursectors. By doing this breakdown, it is possible to understand which areas of Brumadinho's economy were impacted and to what extent that happened.

{\begin{figure}[!h]
\centering

\begin{subfigure}{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/va_agro_2.png}
    \caption{Agriculture}
    \label{fig:gva_agro_time_series}
\end{subfigure}
\hfill
\begin{subfigure}{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/va_ind_2.png}
    \caption{Industry}
    \label{fig:gva_ind_time_series}
\end{subfigure}

%\caption{Sectorial GVA Per Capita treated and synthetic trends.}
%\label{fig:gva_time_series}
\end{figure}}


{\begin{figure}[!h]\ContinuedFloat
\centering

\begin{subfigure}{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/va_serv_2.png}
    \caption{Services}
    \label{fig:gva_serv_time_series}
\end{subfigure}
\hfill
\begin{subfigure}{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/va_adm_2.png}
    \caption{Public Administration}
    \label{fig:gva_adm_time_series}
\end{subfigure}

\caption{Sectorial GVA Per Capita treated and synthetic trends. 
%(Continued)
}
 \label{fig:gva_time_series}
\end{figure}}

Figure \ref{fig:gva_time_series} presents Brumadinho's and each of the synthetic controls' time series for each of the sectoral $GVAPerCapita$ side by side. The graphs show that the series for the Industry and Services sectors display similar trajectories to that of the $GDPPerCapita$ shown in Figure \ref{fig:gdp_time_series}, with positive gaps for 2020 and 2021. However, the Industry sector presents a very small negative gap for 2019 and the Services sector show a large positive gap for that year. For the Agriculture sector there is a positive gap for the first two treatment years and a negative one for the last, but the results seem noisier than that of the Industry and Services sector. For the Public Administration sector, there is a slight negative gap in 2019, followed by two bigger positive gaps in 2020 and 2021, but the results are also noisier. 

{\begin{figure}[!h]
\centering

\begin{subfigure}{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/va_agro_5.png}
    \caption{Agriculture}
    \label{fig:gva_agro_gaps}
\end{subfigure}
\hfill
\begin{subfigure}{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/va_ind_5.png}
    \caption{Industry}
    \label{fig:gva_ind_gaps}
\end{subfigure}

 \caption{
 Sectorial GVA Per Capita gaps.
 }
% \label{fig:gva_gaps}
\end{figure}}

{\begin{figure}[!h]\ContinuedFloat
\centering

\begin{subfigure}{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/va_serv_5.png}
    \caption{Services}
    \label{fig:gva_serv_gaps}
\end{subfigure}
\hfill
\begin{subfigure}{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/va_adm_5.png}
    \caption{Public Administration}
    \label{fig:gva_adm_gaps}
\end{subfigure}

\caption{Sectorial GVA Per Capita gaps. 
 (Continued)
}
\label{fig:gva_gaps}
\end{figure}}

In Figure \ref{fig:gva_gaps} the gaps for each sector are plotted. For the Industry and Services sectors, it becomes clear that the post treatment gaps are much more extreme than the pre treatment gaps obtained, being supporting evidence for the existence of the previously described treatment effects. The gaps series for the Agriculture and Public Administration sectors appear much noisier and it is unclear whether there was an intervention impact or not, although the Agriculture has post treatment gaps that seem more extreme compared to the pre treatment ones than those of the Public Administration sector.

{\begin{figure}[!h]
\centering

\begin{subfigure}{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/va_agro_6.png}
    \caption{Agriculture}
    \label{fig:gva_agro_placebo_gaps}
\end{subfigure}
\hfill
\begin{subfigure}{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/va_ind_6.png}
    \caption{Industry}
    \label{fig:gva_ind_placebo_gaps}
\end{subfigure}

% \caption{
% Sectorial GVA Per Capita placebo gaps.
% }
% \label{fig:gva_placebo_gaps}
\end{figure}}

{\begin{figure}[!h]\ContinuedFloat
\centering

\begin{subfigure}{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/va_serv_6.png}
    \caption{Services}
    \label{fig:gva_serv_placebo_gaps}
\end{subfigure}
\hfill
\begin{subfigure}{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/va_adm_6.png}
    \caption{Public Administration}
    \label{fig:gva_adm_placebo_gaps}
\end{subfigure}

\caption{Sectorial GVA Per Capita placebo gaps. 
% (Continued)
}
\label{fig:gva_placebo_gaps}
\end{figure}}

In Figure \ref{fig:gdp_placebo_gaps} it is possible to see the gabs of the placebo tests and Brumadinho for the 4 sectors. Visual inspection of the graphs show that the post treatment gaps for the Industry and the Services sectors continue to appear extreme, even among the placebo tests. The Agriculture post intervention gaps do not seem to approach extreme levels compared to the placebo tests. Lastly, for the Public Administration sector the post treatment gaps appear to be among the most extreme, however, it is important to notice that the pre treatment gaps are also among the ones with the worst fit, which will correct the large gaps when calculating $RatioMSPE$.

{\begin{figure}[!h]
\centering

\begin{subfigure}{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/va_agro_7.png}
    \caption{Agriculture}
    \label{fig:gva_agro_placebo_distribution}
\end{subfigure}
\hfill
\begin{subfigure}{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/va_ind_7.png}
    \caption{Industry}
    \label{fig:gva_ind_placebo_distribution}
\end{subfigure}

% \caption{
% Sectorial GVA Per Capita placebo gaps.
% }
% \label{fig:gva_placebo_distribution}
\end{figure}}

{\begin{figure}[!h]\ContinuedFloat
\centering

\begin{subfigure}{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/va_serv_7.png}
    \caption{Services}
    \label{fig:gva_serv_placebo_distribution}
\end{subfigure}
\hfill
\begin{subfigure}{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/va_adm_7.png}
    \caption{Public Administration}
    \label{fig:gva_adm_placebo_distribution}
\end{subfigure}

\caption{Sectorial GVA Per Capita placebo distributions. 
% (Continued)
}
\label{fig:gva_placebo_distribution}
\end{figure}}

Figure \ref{fig:gva_placebo_distribution} shows the calculated placebo distributions of $RatioMSPE$ alongside Brumadinho's ratio for each of the 4 sectors. This display helps conclude that the Industry and Services sector had statistically significant impacts from the dam rupture, with both presenting a pseudo p-value of $0$. The Public Administration of the treated unit had a $RatioMSPE$ which is not extreme, with a pseudo p-value of $0.5$, meaning that $50\%$ of the placebo tests had a ratio at least as extreme as that of Brumadinho, leading to the conclusion that there is not enough evidence to reject the null hypothesis of no impact from the dam rupture on the Public Administration's $GVAPerCapita$. The Agriculture sector also presented a ratio that was not extreme enough, rendering a pseudo p-value of $0.182$, which also leads to the conclusion that there is not enough evidence to reject the null hypothesis of no dam rupture effect on the sector's $GVAPerCapita$. 
\\

\section{Robustness} \label{robustness}

\subsection{Downstream Municipalities}
In this subsection, the robustness of the results for $GDPPerCapita$ is evaluated by constraining the donor pool. This is important because the mud from the disaster reached the Paraopeba River and therefore the municipalities downstream of the dam, although there was no physical destruction outside of Brumadinho.

{\begin{figure}[!h]
\centering

\begin{subfigure}{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/pib_municipios_map.png}
    \caption{With downstream municipalities.}
    \label{fig:gdp_matching_map}
\end{subfigure}
\hfill
\begin{subfigure}{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/pib_municipios_map_no_dowsntream.png}
    \caption{Without downstream municipalities.}
    \label{fig:gdp_wo_matching_map}
\end{subfigure}

\caption{
GDP Per Capita matched donor pool maps.
}
\label{fig:gdp_matching_maps}
\end{figure}}

Thus, there might still have been effects from the mud on other downstream municipalities, as well as spillover effects from the impact on Brumadinho. This check is performed by taking the downstream municipalities out of the matching pool, so that the 30 selected units are not from this group. 

\begin{figure}[!h]
\centering
\includegraphics[width=0.7\textwidth]{images/gdp_wo_2.png}
\caption{GDP Per Capita treated and synthetic trends no downstream.}
\label{fig:gdp_wo_time_series}
\end{figure}

Figure \ref{fig:gdp_matching_maps} shows the map of the donor pools generated by matching for $GDP Per Capita$ with and without restricting the inclusion of downstream municipalities.



Figure \ref{fig:gdp_wo_time_series} shows the time series for Brumadinho and the synthetic control created without downstream municipalities. Clearly, this graph looks almost identical to Figure \ref{fig:gdp_time_series} from subsection \ref{gdp_per_capita}, indicating that the results are robust to this restriction.


Figure \ref{fig:gdp_wo_gaps} plots the series of gaps between the synthetic control and the treated unit for this check. This graph further strengthens the hypothesis of robust results, once again being nearly identical to its predecessor in Figure \ref{fig:gdp_gaps}. 

\begin{figure}[!h]
\centering
\includegraphics[width=0.7\textwidth]{images/gdp_wo_5.png}
\caption{GDP Per Capita gaps no downstream.}
\label{fig:gdp_wo_gaps}
\end{figure}

These results indicate that the estimation from subsection \ref{gdp_per_capita} is robust to eliminating municipalities downstream of the Paraopeba River from the donor pool.


\section{Conclusion} \label{conclusion}
This paper analyzed the effects of the Brumadinho dam rupture disaster across 4 main interest variables \interestvariables, using a matching algorithm along with the synthetic control method and placebo tests for inference. It also evaluated heterogeneity of the effect on $GDPPerCapita$ by performing the same analysis on a 4 sector breakdown of $GVAPerCapita$, \foursectors.

The results show that there is a negative and statistically significant impact on the $GDPPerCapita$ variable, with the effect being small in the first treatment year (2019) and increasing to more than $R\$ 100.000,00$ in the last year (2021). This result is in line with what was expected, since it is natural to imagine that a disaster of this magnitude would disrupt the local economy.

For the wage variables, two specifications were presented, one with the regular $Wage$ and another using $LogWage$, a logarithmic transformation of the previous. For both, the resulting gaps are not statistically significant, meaning that there is not enough evidence to reject the null hypothesis of no treatment effect. Additionally, the post treatment trends of Brumadinho and its synthetic control for both of these variables follow a very similar path, indicating that this result is not an issue of low test power\footnote{Test power refers to the ability of a given test to reject the null hypothesis when it is false.}, but that there actually was no effect. 

For $PropEmployed$ the fit was noisier than for the other variables, but the synthetic control still seemed to follow the trend of Brumadinho well. The post treatment calculated gaps were statistically insignificant, so that there was not enough evidence to reject the null hypothesis of no treatment effect from the disaster.

In the heterogeneity analysis, the impact on $GDPPerCapita$ is broken down into the $GVAPerCapita$ impact across 4 different economic sectors, \foursectors. The analysis concluded that the Agriculture and Public Administration sectors did not present statistically significant gaps, with not enough evidence to reject the null hypothesis of no effect from the disaster on these sectors' $GVAPerCapita$. 

The Industry and Services sectors presented statistically significant gaps, which show strong evidence that the disaster impacted them. The Industry was negatively affected throughout all treatment years, which is according to expectation since the dam rupture heavily impacted all mining activities which had an important share of the municipality's GDP. The Services gaps were negative in 2020 and 2021, but here was a large and positive estimated impact for the year of 2019. This last result is interesting and may provide insight into why the estimated negative gap on $GDPPerCapita$ is small in 2019. A plausible theory for this is that the disaster generated the need for services, such as services related to the restoration of the area, which created a temporary increase in the sector's $GVA$. This theory could also explain why the impact on the Industry was low in 2019 compared to the other periods, because this sector could also have been stimulated by the need to rebuild after the disaster, with the construction sub-sector being heavily employed on this task.

In conclusion, $GDPPerCapita$ appears to be the only interest variable affected, having had a negative impact from the accident, while the other variables $Wage$, $LogWage$ and $PropEmployed$ do not present significant effects. Additionally, the main economic sectors affected are Industry and Services, while Agriculture and Public Administration do not present statistically significant effects. 

Despite the results being evaluated by statistical tests and robustness checks, it is important to recognize that these results rely on the standard assumption of validity of the synthetic control model, and the violation of these would result in invalid estimates. However, the only assumption that seems plausible to have been violated is that of common support, especially for the $PropEmployed$ variable, but even for this interest variable the synthetic control appears to have a reasonable fit and the rendered results do not provide evidence of treatment effect, which is better than providing a miss identified impact.
\\

\newpage

%\section{References}
 \printbibliography 
\addcontentsline{toc}{section}{References}

\newpage
% \appendix
% \section{Appendix}

% Reset the figure numbering and change the style
\setcounter{figure}{0} % Option 1: Reset numbering
\renewcommand{\thefigure}{A.\arabic{figure}}



% \begin{figure}[h]
% \centering

% \begin{subfigure}{0.48\textwidth}
%     \centering
%     \includegraphics[width=\textwidth]{images/pib_municipios_map.png}
%     \caption{GDP Per Capita}
%     \label{fig:gdp_map}
% \end{subfigure}
% \hfill
% \begin{subfigure}{0.48\textwidth}
%     \centering
%     \includegraphics[width=\textwidth]{images/pib_municipios_map.png}
%     \caption{Another variable}
%     \label{fig:another}
% \end{subfigure}

% \caption{Comparison of two features.}
% \label{fig:two_side_by_side}
% \end{figure}


% \begin{figure}[h]
% \centering

% \begin{minipage}{0.48\textwidth}
%     \centering
%     \includegraphics[width=\textwidth]{images/gdp_2.png}
%     \caption{Donor pool for GDP Per Capita.}
%     \label{fig:gdp_map}
% \end{minipage}
% \hfill
% \begin{minipage}{0.48\textwidth}
%     \centering
%     \includegraphics[width=\textwidth]{images/gdp_2.png}
%     \caption{Another caption here.}
%     \label{fig:another}
% \end{minipage}

% \end{figure}






% {\begin{figure}[!h]
% \centering

% % --- First row ---
% \begin{subfigure}{0.48\textwidth}
%     \centering
%     \includegraphics[width=\textwidth]{images/va_agro_2.png}
%     \caption{Agriculture}
%     \label{fig:gva_agro_time_series}
% \end{subfigure}
% \hfill
% \begin{subfigure}{0.48\textwidth}
%     \centering
%     \includegraphics[width=\textwidth]{images/va_ind_2.png}
%     \caption{Industry}
%     \label{fig:gva_ind_time_series}
% \end{subfigure}

% \vspace{1em} % add vertical spacing between rows

% % --- Second row ---
% \begin{subfigure}{0.48\textwidth}
%     \centering
%     \includegraphics[width=\textwidth]{images/va_serv_2.png}
%     \caption{Services}
%     \label{fig:gva_serv_time_series}
% \end{subfigure}
% \hfill
% \begin{subfigure}{0.48\textwidth}
%     \centering
%     \includegraphics[width=\textwidth]{images/va_adm_2.png}
%     \caption{Public Administration}
%     \label{fig:gva_adm_time_series}
% \end{subfigure}

% \caption{Sectorial GVA Per Capita treated and synthetic trends.}
% \label{fig:gva_time_series}
% \end{figure}}

\end{document}